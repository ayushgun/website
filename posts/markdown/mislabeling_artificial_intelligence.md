# Mislabeling Artificial Intelligence

> June 29, 2023

Yesterday, I was scrolling through my LinkedIn feed when I came across a spreadsheet software startup that claimed to have "harnessed the mighty powers" of artificial intelligence to "supercharge" users productivity. The post was adorned with buzzwords like "neural networks" and "deep learning." Upon examining the software myself, though, what I found was a simply a series of basic if-else rules merely mislabeled as artificial intelligence.

Over the last year (namely since the release of [ChatGPT](https://openai.com/chatgpt)), artificial intelligence has often misapplied to technologies that do not embody its core principles, such as learning and reasoning. examines the technological aspects of AI, identifies common instances of mislabeling, and discusses the implications of this misrepresentation on the development and perception of AI technologies.

## Cases of Mislabeling

Artificial Intelligence aims to create machines capable of intelligent behavior, primarily through learning from data, making decisions, and improving over time. Despite these clear technological foundations, the term AI has been increasingly used to describe a range of technologies that do not possess these core attributes. For instance, rule-based systems, which operate on predefined rules and heuristics, are often mislabeled as AI despite not having the ability to learn or adapt. Similarly, basic automation scripts and data analytics, which might involve simple statistical analysis or data visualization, are incorrectly labeled as AI. Automation can be a component of AI systems when it involves decision-making based on learning, but not all automation involves AI.

## Technical Implications

In my opinion, the mislabeling of technologies as AI dilutes the understanding of what AI truly represents, leading to confusion and misconceptions among the public and stakeholders regarding the capabilities of AI systems. This is particularly concerning as it can lead to growing unrealistic expectations among the public. The misrepresentation of basic technologies as AI can divert attention and resources away from real (and exciting!) AI research and development. This is detrimental to the progress in the field, as it can lead to the misallocation of funding and a lack of focus on areas that are crucial for the advancement of AI.

Worst of all, it obscures the ethical and legal considerations that are unique to AI systems. For example, bias in machine learning models or the interpretability (e.g., [hallucination](<https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)>)) of AI decisions are critical issues that need to be addressed. When basic technologies are labeled as AI, these considerations are not given the attention they require.
